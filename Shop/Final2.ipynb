{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('hadoop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['idx','access_date','access_time','access_page','access_referer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ip = data[data['item_type']=='cart']['access_ip'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dict_ip insert key is ip item is values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ip = dict.fromkeys(unique_ip)   #dict key 생성\n",
    "\n",
    "for i in dict_ip.keys():\n",
    "    dict_ip[i] = []\n",
    "\n",
    "#-----------------------------------------------#\n",
    "\n",
    "for i in range(len(data)):          #dict value 삽입\n",
    "    if (data['access_ip'].iloc[i] in dict_ip.keys()):\n",
    "        key = data['access_ip'].iloc[i]\n",
    "        dict_ip[key].append(data['item_id'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in dict_ip.items():\n",
    "    dict_ip[i] = list(map(str,j))        #dict value를 string으로 매핑\n",
    "    \n",
    "#------------------------------------------------#\n",
    "#dict의 벨류가 4 미만이면 삭제\n",
    "dict_ip = {key:value for key, value in dict_ip.items() if len(value) >4} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_item = []       #dict의 마지막 아이템을 카트 아이템배열에 넣음\n",
    "for i,j in dict_ip.items():\n",
    "    cart_item.append(j[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = []      #column이름을 string으로 변환\n",
    "for i in range(14):\n",
    "    columns_name.append(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DataFrame New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dict_ip,orient='index',columns=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.applymap(lambda x: x is None)         #None값들 삭제\n",
    "cols = df.columns[(mask).any()]\n",
    "for col in df[cols]:\n",
    "    df.loc[mask[col], col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = []                 #item들을 뽑아서 한 row씩 한 리스트로 묶어 배열 생성\n",
    "for i in range(len(df)):\n",
    "    item_list.append(df.iloc[i,:].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(3032)\n",
    "df = df.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_tmpfile('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(item_list, size=1 ,window=5, min_count=1,workers=5)\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv  \n",
    "vocabs = word_vectors.vocab.keys() #vocabs has keys that is item number\n",
    "\n",
    "#word_vectors_list has values that is vector value from item number\n",
    "word_vectors_list = [word_vectors[v] for v in vocabs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):            #word2vec value를 df로 넣음\n",
    "    for j in range(len(df.iloc[i])):\n",
    "        key=str(df.iloc[i,j])\n",
    "        df.iloc[i,j] = word_vectors[key].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split && Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from heapq import nsmallest\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df.drop('13',axis=1)\n",
    "y_data = df['13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750.0443375110626\n"
     ]
    }
   ],
   "source": [
    "seed = 6\n",
    "test_size = 0.2\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=test_size, random_state=seed)\n",
    "model = xgb.XGBClassifier(n_estimators=1000,max_depth=8,learning_rate=0.1,subsample=0.5)\n",
    "time1 = time.time()\n",
    "model.fit(X_train,y_train)\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 추천 시작\n",
      "1 번째 추천(2000건)에 걸린 시간(초): 123.21332740783691\n",
      "1 번째 데이터 한개당 걸린 시간 : 0.06160666370391846\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.954\n",
      "----------------------------------------------------\n",
      "2 번째 추천 시작\n",
      "2 번째 추천(2000건)에 걸린 시간(초): 120.60031747817993\n",
      "2 번째 데이터 한개당 걸린 시간 : 0.06030015873908996\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.9435\n",
      "----------------------------------------------------\n",
      "3 번째 추천 시작\n",
      "3 번째 추천(2000건)에 걸린 시간(초): 120.84765791893005\n",
      "3 번째 데이터 한개당 걸린 시간 : 0.06042382895946503\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.941\n",
      "----------------------------------------------------\n",
      "4 번째 추천 시작\n",
      "4 번째 추천(2000건)에 걸린 시간(초): 118.93876552581787\n",
      "4 번째 데이터 한개당 걸린 시간 : 0.05946938276290894\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.951\n",
      "----------------------------------------------------\n",
      "5 번째 추천 시작\n",
      "5 번째 추천(2000건)에 걸린 시간(초): 122.44438576698303\n",
      "5 번째 데이터 한개당 걸린 시간 : 0.06122219288349152\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.936\n",
      "----------------------------------------------------\n",
      "6 번째 추천 시작\n",
      "6 번째 추천(2000건)에 걸린 시간(초): 119.56845474243164\n",
      "6 번째 데이터 한개당 걸린 시간 : 0.05978422737121582\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.943\n",
      "----------------------------------------------------\n",
      "7 번째 추천 시작\n",
      "7 번째 추천(2000건)에 걸린 시간(초): 120.71254277229309\n",
      "7 번째 데이터 한개당 걸린 시간 : 0.06035627138614655\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.8675\n",
      "----------------------------------------------------\n",
      "8 번째 추천 시작\n",
      "8 번째 추천(2000건)에 걸린 시간(초): 127.64457297325134\n",
      "8 번째 데이터 한개당 걸린 시간 : 0.06382228648662568\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.942\n",
      "----------------------------------------------------\n",
      "9 번째 추천 시작\n",
      "9 번째 추천(2000건)에 걸린 시간(초): 123.72795128822327\n",
      "9 번째 데이터 한개당 걸린 시간 : 0.061863975644111634\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.94\n",
      "----------------------------------------------------\n",
      "10 번째 추천 시작\n",
      "10 번째 추천(2000건)에 걸린 시간(초): 121.61899018287659\n",
      "10 번째 데이터 한개당 걸린 시간 : 0.06080949509143829\n",
      "예측한 값과 가까운 아이템 5개의 Accuracy : 0.9435\n",
      "----------------------------------------------------\n",
      "추천 정확도의 평균 : 0.9361499999999999\n",
      "데이터 한개당 걸린 시간의 평균 : 0.060965848302841186\n"
     ]
    }
   ],
   "source": [
    "avg_time = []\n",
    "avg_acu = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(i+1, \"번째 추천 시작\")\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    start = time.time()\n",
    "    seed = i\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=test_size, random_state=seed)\n",
    "    prediction = model.predict(X_test)\n",
    "    end = time.time()\n",
    "    print(i+1, \"번째 추천(2000건)에 걸린 시간(초):\", end-start)\n",
    "    print(i+1, \"번째 데이터 한개당 걸린 시간 :\", (end-start)/2000)\n",
    "    \n",
    "    result['predicted'] = prediction\n",
    "    result['Y_test'] = y_test.tolist()\n",
    "    \n",
    "    #예측값과 근사한 값 5개 출력\n",
    "    vector_list = []\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        vector_list.append(nsmallest(6, word_vectors_list, key=lambda x: abs(x-result['predicted'].iloc[i])))\n",
    "    \n",
    "    result['Nearby5'] = pd.Series(vector_list)\n",
    "    for i in range(len(result)):\n",
    "        result['Nearby5'].iloc[i] = vector_list[i]\n",
    "    \n",
    "    T_F = []\n",
    "    for i in range(len(result)):\n",
    "        if result['Y_test'].iloc[i] in result['Nearby5'].iloc[i]:\n",
    "            T_F.append('True')\n",
    "        else:\n",
    "            T_F.append('False')\n",
    "    \n",
    "    result['T_F'] = T_F\n",
    "    \n",
    "    print(\"예측한 값과 가까운 아이템 5개의 Accuracy :\", len(result[result['T_F']=='True'])/len(result))\n",
    "    \n",
    "    \n",
    "    avg_acu.append(len(result[result['T_F']=='True'])/len(result))\n",
    "\n",
    "    \n",
    "    avg_time.append((end - start)/2000)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "print(\"추천 정확도의 평균 :\", sum(avg_acu)/len(avg_acu))\n",
    "print(\"데이터 한개당 걸린 시간의 평균 :\", sum(avg_time)/len(avg_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
